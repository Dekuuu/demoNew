springfox:
  documentation:
    swagger:
      v2:
        path: /api-docs
server:
  port: 9080

#   mybatis_config
mybatis:
  mapper-locations: classpath:mapper/**/*.xml

  #datasource
spring:
  application:
    name: demo-service
  cloud:
    nacos:
      discovery:
        server-addr: ${NACOS_SERVER}
        namespace: 6d7ab29c-7da9-488c-a319-0f4219de7b1c
        group: dev
  jackson:
    time-zone: GMT+8
    date-format: yyyy-MM-dd HH:mm:ss
  datasource:
    driverClassName: com.mysql.jdbc.Driver
    .jdbc-url: jdbc:mysql://${mysql.ip}:${mysql.port}/${mysql.database}
    username: ${mysql.user}
    password: ${mysql.password}
    initSize: 5
    maxActive: 20
    minIdle: 5
    maxWait: 5000
    testOnReturn: true
    type: com.alibaba.druid.pool.DruidDataSource
#    slave1:
#      driverClassName: com.mysql.jdbc.Driver
#      .jdbc-url: jdbc:mysql://192.168.229.131:3306/test_slave
#      username: root
#      password: root
#      initSize: 5
#      maxActive: 20
#      minIdle: 5
#      maxWait: 5000
#      testOnReturn: true
    #============== kafka ==================
  # 指定kafka 代理地址，可以多个
  kafka:
    bootstrap-servers: ${kafka.server}
    producer:
      retries: 0
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: test1-group
      auto-offset-reset: earliest
      enable-auto-commit: true
      auto-commit-interval: 100
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      missing-topics-fatal: false
  redis:
    #数据库索引
    database: 0
    host: ${redis.ip}
    port: ${redis.port}
    password:
    jedis:
      pool:
        #最大连接数
        max-active: 8
        #最大阻塞等待时间(负数表示没限制)
        max-wait: -1
        #最大空闲
        max-idle: 8
        #最小空闲
        min-idle: 0
        #连接超时时间
    timeout: 10000

#elasticsearch:
#  user:
#  password:
#  host: 172.25.22.60:9200


feign:
  hystrix:
    enabled: true
# 设置hystrix的超时时间，默认是1000ms
hystrix:
  command:
    default:
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 10000
#  =============== provider  =======================
#
#  spring.kafka.producer.retries=0
#  # 每次批量发送消息的数量
#  spring.kafka.producer.batch-size=16384
#  spring.kafka.producer.buffer-memory=33554432
#
#  # 指定消息key和消息体的编解码方式
#  spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#  spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#
#  #=============== consumer  =======================
#  # 指定默认消费者group id
#  spring.kafka.consumer.group-id=test-hello-group
#
#  spring.kafka.consumer.auto-offset-reset=earliest
#  spring.kafka.consumer.enable-auto-commit=true
#  spring.kafka.consumer.auto-commit-interval=100
#
#  # 指定消息key和消息体的编解码方式
#  spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#  spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
